<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>HomeLab Documents - homelab</title><link href="https://ignorantforager.com/" rel="alternate"/><link href="https://ignorantforager.com/feeds/homelab.atom.xml" rel="self"/><id>https://ignorantforager.com/</id><updated>2025-10-08T00:00:00-07:00</updated><entry><title>Building a 300TB NAS and the Hardware That Hated Me</title><link href="https://ignorantforager.com/building-a-300tb-nas-and-the-hardware-that-hated-me.html" rel="alternate"/><published>2025-10-08T00:00:00-07:00</published><updated>2025-10-08T00:00:00-07:00</updated><author><name>Cadence James</name></author><id>tag:ignorantforager.com,2025-10-08:/building-a-300tb-nas-and-the-hardware-that-hated-me.html</id><summary type="html">&lt;h2&gt;Part 1: Building a 300TB NAS and the Hardware That Hated Me&lt;/h2&gt;
&lt;p&gt;It started with an exciting vision: to build a true "endgame" home server. The goal was to consolidate my sprawling setup into a single, powerful All-in-One server. I already had the chassis, a 45Drives HL15, and the storage—fifteen 20TB Seagate drives ready to go. Now, I just needed to pick the brains of the operation.&lt;/p&gt;
&lt;p&gt;After a bit of research, I landed on what felt like a killer combo for a TrueNAS SCALE build.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Final Parts List (after all my troubleshooting):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Case:&lt;/strong&gt; 45Drives HL15&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Motherboard:&lt;/strong&gt; Supermicro …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;h2&gt;Part 1: Building a 300TB NAS and the Hardware That Hated Me&lt;/h2&gt;
&lt;p&gt;It started with an exciting vision: to build a true "endgame" home server. The goal was to consolidate my sprawling setup into a single, powerful All-in-One server. I already had the chassis, a 45Drives HL15, and the storage—fifteen 20TB Seagate drives ready to go. Now, I just needed to pick the brains of the operation.&lt;/p&gt;
&lt;p&gt;After a bit of research, I landed on what felt like a killer combo for a TrueNAS SCALE build.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Final Parts List (after all my troubleshooting):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Case:&lt;/strong&gt; 45Drives HL15&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Motherboard:&lt;/strong&gt; Supermicro X13SAE-F&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CPU:&lt;/strong&gt; Intel Core i5-13500 (13th Gen)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CPU Cooler:&lt;/strong&gt; Noctua NH-D9L (2x NF-A9 92mm fan)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PSU:&lt;/strong&gt; Seasonic GX-1000&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Boot Drives:&lt;/strong&gt; 2x 1TB Samsung 990 EVO (Mirrored)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RAM:&lt;/strong&gt; 2x Supermicro 32GB DDR5-4800 ECC UDIMM&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HBA:&lt;/strong&gt; LSI 9300-16i&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OS:&lt;/strong&gt; TrueNAS SCALE&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hard Drives:&lt;/strong&gt; 4x 20TB Seagate Iron Wolf Pro, 11x Refurbished 20TB Seagate Exos X20&lt;blockquote&gt;
&lt;p&gt;I originally was going to build with all Seagate Iron Wolf Pros and purchased five to start. However, I soon learned that refurbished drives can be just as reliable, if not more so (as you'll see later on).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With everything ordered, I was ready for a straightforward build. What I got instead was a multi-week saga of troubleshooting.&lt;/p&gt;
&lt;h3&gt;Chapter 1: The DOA Motherboard and RAM Fiasco&lt;/h3&gt;
&lt;p&gt;I started assembling the build, eager to get it running. The first snag hit when I tried to install the RAM. Originally, I had bought two sticks of "Samsung 32GB DDR5 ECC RDIMM." When they arrived, I realized my mistake: RDIMM ("Registered") modules are for heavy-duty enterprise servers and don't work with my consumer-grade CPU and workstation motherboard. The sticks literally wouldn't fit.&lt;/p&gt;
&lt;p&gt;Frustrated with myself for this simple oversight, I sent them back and ordered a non-ECC kit that would work: a "Crucial Pro 96GB DDR5 RAM Kit (2x48GB)." With the new RAM installed, I finished the build. I hit the power switch. And… nothing. Not a single click, fan spin, or light.&lt;/p&gt;
&lt;p&gt;This kicked off my first deep dive into troubleshooting. I started with the most likely culprits. First, the PSU. I unplugged the 24-pin motherboard connector, attached the PSU’s included jumper, and everything in the case (PSU fan, case fans) spun to life. So, the PSU was good. Next, I suspected a short circuit. I pulled the entire motherboard out of the case, placed it on its box, connected only the CPU, the new Crucial RAM, and the 24-pin and 8-pin power cables. I jumped the power pins with a screwdriver. Still dead. The real clue was the lack of any standby "heartbeat" LED. A server board (and especially one with IPMI) should have a light on, even when "off" and mine was completely dark. The board I bought used from eBay seemed DOA. Just to make sure, I busted out a brand new PSU that I had laying around from a previous desktop build a few years ago. I hooked this up with the same minimal components. All the same indications. No power on unless I jumped the 24-pin cable. This verified that the PSU was good. Just for good measure, I went through the motherboard manual and identified any jumpers that might be set in the wrong position and might prohibit the board from powering on. I cleared the CMOS and even replaced the CMOS battery entirely. All to no avail. The motherboard was indeed DOA. I initiated a return and refund, then ordered the same model, but this time from a third-party seller on Amazon. (The original motherboard was from a seller on eBay with a great reputation. It looks like it was an unfortunate situation and no fault of theirs. I don't blame them whatsoever).&lt;/p&gt;
&lt;h3&gt;Chapter 2: The Zombie Board and the BIOS Mystery&lt;/h3&gt;
&lt;p&gt;The second motherboard arrived. This time, when I plugged it in, I got that beautiful little green standby light. It was alive! But when I jumped the power pins, it still refused to turn on. The board had power but was &lt;em&gt;still&lt;/em&gt; not POST-ing. My first thought was a configuration issue, so I turned to the IPMI remote management. I connected it to my network, found its IP, and tried the default &lt;code&gt;admin&lt;/code&gt;/&lt;code&gt;admin&lt;/code&gt; credentials. They didn't work. I found a sticker on the board with the motherboards unique BMC password, but those credentials didn't work either. Supermicro does have a tool to change the BMC password or even factory reset the BMC entirely. However, it needs the system to boot in order to load a DOS image or use the UEFI shell to run the tool. As I couldn't even boot my system, I was locked out.&lt;/p&gt;
&lt;p&gt;I ended up swapping out the RAM thinking that maybe for some reason the Crucial RAM I had purchased wasn't compatible with the setup. I ended up going with two sticks of "Supermicro 32GB DDR5-4800 ECC UDIMM". This didn't solve the issue either, unfortunately. This led me to a new theory: what if the BIOS was too old to recognize my 13th Gen CPU? The motherboard was originally released during the 12th generation series of CPUs. I did question myself on this one. I thought an incompatible CPU would still let the system power on, maybe giving a beep code or a "CPU not supported" message on the screen. I never imagined it would cause a complete failure to POST. But with all other variables exhausted, it was the only theory that made sense.&lt;/p&gt;
&lt;p&gt;To test it, I ordered the cheapest compatible 12th Gen CPU I could find at the time, an Intel i3-12100F, to act as a "key." I swapped it in, and just like that, the server powered on and POSTed. It worked. The BIOS incompatibility was the culprit.&lt;/p&gt;
&lt;p&gt;With the system finally booting, I updated the BIOS to the latest version. Annoyingly, even after the update, the IPMI credentials still did not work. So, I booted into the UEFI shell, ran Supermicro's IPMICFG tool to factory reset the BMC and, &lt;em&gt;finally&lt;/em&gt;, I was able to log in and set a new password. After everything was verified working on my original CPU, I returned the i3-12100F.&lt;/p&gt;
&lt;h3&gt;Chapter 3: An HBA Saga and a Bad Drive&lt;/h3&gt;
&lt;p&gt;With the server booting with the i5-13500 and proper ECC RAM, it was time for storage. I installed my HBA card from my previous server, which I had flashed to IT Mode years ago. I booted up TrueNAS, and… no drives.&lt;/p&gt;
&lt;p&gt;After a slew of research, I learned that my "HBA" card that I had used in the past wasn't actually an HBA card at all, but rather a SAS Expander. Meant to be used &lt;em&gt;with&lt;/em&gt; an HBA. My old server must have had a built-in HBA on the motherboard that I either didn't realize or completely forgot about. With this understanding, I ordered a proper, modern HBA: an LSI 9300-16i. As soon as I installed it, TrueNAS detected all 15 drives. Success!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For structuring the storage, I opted for a single ZFS pool built from three separate, 5-drive RAIDZ2 vdevs. This specific layout, rather than one massive 15-drive vdev, offers two critical advantages for an all-in-one server. Firstly, it dramatically improves performance; since ZFS stripes data across vdevs, having three of them provides roughly triple the random I/O operations per second (IOPS), which is essential for keeping virtual machines and applications like Plex feeling responsive. Secondly, it drastically increases safety and reduces rebuild times. Each vdev is configured as RAIDZ2, meaning every 5-drive group can lose any two drives without any data loss. Should a drive fail, ZFS only needs to resilver the data within that single, smaller vdev. This process is significantly faster and puts far less stress on the remaining drives than rebuilding a giant 15-drive array, which is a crucial consideration for the long-term health of a pool built with massive 20TB drives.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Before loading any data, my first order of business was to kick off a ZFS scrub. This is ZFS's built-in data integrity check, where it systematically reads every block of data across all the drives to ensure it matches stored checksums, proactively searching for any silent corruption or hardware errors. On a new, empty pool, it should be fast, but  still take a few minutes to check all the ZFS metadata distributed across the drives. It finished in &lt;strong&gt;one second&lt;/strong&gt; with zero errors. This was a huge red flag. It meant the scrub wasn't actually running.&lt;/p&gt;
&lt;p&gt;This led me down yet another troubleshooting journey. The HBA, an LSI 9300-16i, was showing up as two separate controllers. Using the TrueNAS shell, I verified the firmware of the controllers using &lt;code&gt;sas3flash -listall&lt;/code&gt;. This showed me both controllers and the firmware they were on: "16.00.10.00". While this was the latest firmware for the device, there is a TrueNAS specific firmware "16.00.12.00". I downloaded the TrueNAS firmware from their forums (as far as I'm aware, the TrueNAS specific firmware isn't even available on the LSI website).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I did end up having to create a dataset in my pool as &lt;code&gt;/mnt/mainpool/temp&lt;/code&gt;. I then created an SMB share so I could mount it on my computer and transfer the firmware to this dataset to use. I also use this "temporary" dataset later on as you'll see.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I changed directories to the temp dataset and used the SAS 3 Flash tool:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;sas3flash -o -f SAS9300-16i_IT.bin
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then I did the listall command again, but saw that only the first controller was flashed. I tried to flash the second controller specifically with&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;sas3flash -c 1 -o -f SAS9300-16i_IT.bin
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;(the '-c 1' portion points the flash tool to the second controller). This didn't work. I then attempted using the flag "-fwall" to update the firmware on ALL controllers. That didn't work either. I was stumped. I pored over a bunch of forum posts and eventually came across one that said to use the flag &lt;code&gt;-nossid&lt;/code&gt;. I attempted running this full command: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;sas3flash -c 1 -o -f SAS9300-16i_IT.bin -nossid
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;and it finally worked. This command essentially tells the flash tool to ignore the error it was getting about the SubSystem ID not matching. Both of the controllers were now on the latest "16.00.12.00", TrueNAS specific firmware.&lt;/p&gt;
&lt;p&gt;I attempted to run the scrub again, but still no dice. It completed immediately with zero issues. Frustrated, I decided to run a simple stress test: write a large file and check its integrity. The write was fast, but when I ran a checksum on the file, &lt;code&gt;dmesg&lt;/code&gt; lit up with "Unrecovered read error" from drive &lt;code&gt;/dev/sdj&lt;/code&gt;. This was it. One of my brand new 20TB drives was faulty, and this critical hardware error was causing the ZFS scrub to abort.&lt;/p&gt;
&lt;p&gt;To be 100% sure, I ran a SMART test on the suspect drive. It failed within five minutes and just 10% into the test. That was all the proof I needed. I purchased a new drive to get the system up and running immediately and started the RMA process for the failed one, which will soon become my first cold spare. After replacing the drive, the resilver was successful, and a new scrub ran perfectly.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;As an interesting note here, the drive that failed was one of the five original, brand new, Iron Wolf Pros that I had bought. This has definitely improved my, already good, outlook on using refurbished drives. I ended up replacing it with a refurbished Seagate Exos X20.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The hardware was, at long last, stable.&lt;/p&gt;
&lt;h3&gt;Chapter 4: The Great Migration&lt;/h3&gt;
&lt;p&gt;With the server ready, it was time to move approximately 40TB of data from my old server. I set up a direct 10GbE link between them. I set up a network between the two using "192.168.10.2/24" on my older server and "192.168.10.3/24" on my new server. My tool of choice was &lt;code&gt;rsync&lt;/code&gt;, and I included the &lt;code&gt;--checksum&lt;/code&gt; flag to guarantee data integrity.&lt;/p&gt;
&lt;p&gt;The first few small folders transferred fine. But when I started transferring my movies folder, the transfer got stuck for over an hour on "receiving incremental file list" before even starting the copy. I realized the &lt;code&gt;--checksum&lt;/code&gt; flag was forcing the old server to read every single byte of data &lt;em&gt;before&lt;/em&gt; the transfer. I killed the job, removed the flag and re-ran the command. It started copying almost immediately. The &lt;code&gt;rsync&lt;/code&gt; tool is robust and can pick up where it left off, and on a direct, stable link, the chance of a transfer error is tiny. I decided the speed increase was worth the minuscule risk. Even then, the transfer was slow, averaging 30-50MB/s with occasional jumps over 100MB/s.&lt;/p&gt;
&lt;p&gt;To manage this multi-day transfer, I used a crucial tool: &lt;code&gt;tmux&lt;/code&gt;. It lets you run terminal sessions that persist even if you get disconnected. My initial setup was simple:
1.  Start a session: &lt;code&gt;tmux&lt;/code&gt;
2.  Elevate to root: &lt;code&gt;sudo -i&lt;/code&gt;
3.  Start the copy using the command:
    &lt;code&gt;rsync -rltvhP root@192.168.10.2:/mnt/Zenodotus/Media/movies/ /mnt/mainpool/media/movies&lt;/code&gt;
4.  Detach, leaving the job running: 'Ctrl+b, d'.&lt;/p&gt;
&lt;p&gt;My movie folder transferred about 6.7TB in about 48 hours. Not great. I moved ahead with copying my television folder, knowing it would take a significant amount of time to fully transfer. It was about a quarter of the way through copying my television folder that I thought about updating my network settings on the direct link to use an MTU of 9000 (Jumbo Frames). Since it was a direct link, there was no risk of dropped packets that can happen on a switched network and it had the possibility of increasing the transfer speed. Unfortunately that didn't increase the speed at all. The only explanation left was my old server's fragmented ZFS pool as the bottleneck and I couldn't think of anything else to increase the speed. At least on the hardware side.&lt;/p&gt;
&lt;p&gt;About halfway through copying my television folder, I did decide to try and speed things up by splitting the transfer into two parallel &lt;code&gt;rsync&lt;/code&gt; jobs. The way I did this was to create two text files with half of the remaining folders in one text file and the rest in the second text file. Then I would start the rsync job again, but this time point the source at these files. Managing this in &lt;code&gt;tmux&lt;/code&gt; was easy: I created a second window (Ctrl+b, c) for the second &lt;code&gt;rsync&lt;/code&gt; job. I could then switch between them with 'Ctrl+b, 0' and 'Ctrl+b, 1'. In the first window, I ran the command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;rsync&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;rltvhP&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;files&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;from&lt;/span&gt;&lt;span class="o"&gt;=/&lt;/span&gt;&lt;span class="n"&gt;mnt&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;mainpool&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;temp&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;tv&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="mf"&gt;-1.&lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="mf"&gt;@192.168.10.2&lt;/span&gt;&lt;span class="o"&gt;:/&lt;/span&gt;&lt;span class="n"&gt;mnt&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Zenodotus&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Media&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Television&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;mnt&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;mainpool&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;media&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;television&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In the second window:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;rsync&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;rltvhP&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;files&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;from&lt;/span&gt;&lt;span class="o"&gt;=/&lt;/span&gt;&lt;span class="n"&gt;mnt&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;mainpool&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;temp&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;tv&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="mf"&gt;-2.&lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="mf"&gt;@192.168.10.2&lt;/span&gt;&lt;span class="o"&gt;:/&lt;/span&gt;&lt;span class="n"&gt;mnt&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Zenodotus&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Media&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Television&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;mnt&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;mainpool&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;media&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;television&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To my surprise, neither job slowed down and I was now getting nearly double the total throughput.&lt;/p&gt;
&lt;p&gt;It was about this time that I wished I was capturing stats. I realized the default &lt;code&gt;tmux&lt;/code&gt; history was only 2,000 lines, which wasn't enough to capture the full log. While the jobs were running, I increased the buffer:
&lt;code&gt;set-option -g history-limit 100000&lt;/code&gt;. This wouldn't recover the old history, but it ensured I could capture everything from then on. If I were to do this again, I’d set this at the very beginning, before I ran the initial rsync commands. Once a job finished, I could save the log with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;tmux capture-pane -pS -100000 -t 0:0 &amp;gt; /mnt/mainpool/temp/rsync_job1_log.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;(the &lt;code&gt;-t 0:0&lt;/code&gt; targets the first session, first window of &lt;code&gt;tmux&lt;/code&gt;. For the second window it would be &lt;code&gt;-t 0:1&lt;/code&gt;). I plan on going through and attempting to get any stats I can (e.g. average size of files transferred, average transfer speed, and average transfer time per file). It's not needed now that the transfer is fully complete, but it'd be nice to reference and see.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Ideally I'd love to create something with those stats that could make /r/dataisbeautiful proud.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Once this week-long migration was finished, I went through and ran the original rsync command again on both movies and tv shows in order to capture anything I missed from the split rsync jobs or any new files that appeared while running the jobs. There were only a few files and took less than an hour.&lt;/p&gt;
&lt;h3&gt;To Be Continued…&lt;/h3&gt;
&lt;p&gt;This build fought me to the very end. When I finally looked at the stable, running server, I realized that every single component (the motherboard, PSU, CPU, RAM, HBA, and even a hard drive) had been swapped out at least once. It was a true Server of Theseus, if you will. Rebuilt piece by piece on its journey to completion.&lt;/p&gt;
&lt;p&gt;After a journey that tested every bit of my patience, the physical build is complete. The hardware is stable and the data is home, but the project is only half done. In Part 2, I'll tackle the software: installing the full app stack, migrating my Plex metadata, and finally bringing this 300TB beast fully to life.&lt;/p&gt;</content><category term="homelab"/><category term="nas"/><category term="truenas"/><category term="hardware"/><category term="homelab"/><category term="storage"/></entry><entry><title>Fixing Plex Docker Failures - Resolving Disk Space Issues and Optimizing Storage</title><link href="https://ignorantforager.com/fixing-plex-docker-failures-resolving-disk-space-issues-and-optimizing-storage.html" rel="alternate"/><published>2025-02-11T00:00:00-08:00</published><updated>2025-02-11T00:00:00-08:00</updated><author><name>Cadence James</name></author><id>tag:ignorantforager.com,2025-02-11:/fixing-plex-docker-failures-resolving-disk-space-issues-and-optimizing-storage.html</id><summary type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Managing disk space efficiently is crucial for maintaining a stable Plex Media Server, especially when running it as a Docker container on an Ubuntu Live Server VM. Recently, I encountered a critical issue where Plex failed to start and transcode media due to insufficient disk space. Additionally, system updates were blocked due to a full root partition. This post details the root cause analysis, troubleshooting steps, and resolution strategies, including mounting a secondary drive for Plex storage. By following these steps, you can prevent similar issues and optimize your Plex server’s performance.&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;&lt;strong&gt;Issue Summary:&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Plex Media Server, running …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Managing disk space efficiently is crucial for maintaining a stable Plex Media Server, especially when running it as a Docker container on an Ubuntu Live Server VM. Recently, I encountered a critical issue where Plex failed to start and transcode media due to insufficient disk space. Additionally, system updates were blocked due to a full root partition. This post details the root cause analysis, troubleshooting steps, and resolution strategies, including mounting a secondary drive for Plex storage. By following these steps, you can prevent similar issues and optimize your Plex server’s performance.&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;&lt;strong&gt;Issue Summary:&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Plex Media Server, running as a Docker container on an Ubuntu Live Server VM (hosted on Proxmox), was failing to start properly. Additionally, Plex playback issues occurred when attempting to transcode media, displaying an error stating, "There's not enough space to convert this item." Furthermore, attempting to update Ubuntu (&lt;code&gt;sudo apt update &amp;amp;&amp;amp; sudo apt upgrade&lt;/code&gt;) resulted in the following error:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;You&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;don&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;t have enough free space in /var/cache/apt/archives/.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h4&gt;&lt;strong&gt;Error Messages from Plex Logs:&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Upon examining the Plex logs, the following critical error was identified:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nx"&gt;Starting&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Plex&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Media&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Server&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;you&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;can&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;ignore&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;libusb_init&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;error&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;libc&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="nx"&gt;abi&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;terminating&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;with&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;uncaught&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;exception&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;of&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;type&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nx"&gt;runtime_error&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Codecs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Initialize&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="nx"&gt;boost&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nx"&gt;filesystem&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nx"&gt;create_directories&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;No&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;space&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;left&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;on&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;device&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;system&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/config/Library/Application Support/Plex Media Server/Codecs/e613bce-97f23d579c1001d8e9cc0d2e-linux-x86_64&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/config/Library/Application Support/Plex Media Server/Codecs/e613bce-97f23d579c1001d8e9cc0d2e-linux-x86_64&amp;quot;&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
&lt;span class="o"&gt;******&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;PLEX&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;MEDIA&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;SERVER&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;CRASHED&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;CRASH&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;REPORT&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;WRITTEN&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;config&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;Library&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;Application&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Support&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;Plex&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Media&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Server&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;Crash&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Reports&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;&lt;strong&gt;Root Cause Analysis:&lt;/strong&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Root Filesystem Full:&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Running &lt;code&gt;df -h&lt;/code&gt; revealed that the root partition (&lt;code&gt;/dev/mapper/ubuntu--vg-ubuntu--lv&lt;/code&gt;) was &lt;strong&gt;100% full&lt;/strong&gt;, preventing Plex from writing necessary codec files and causing transcode failures.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Plex container's &lt;code&gt;/config&lt;/code&gt; directory was mapped to &lt;code&gt;/var/plex/config&lt;/code&gt;, which resided on the full root partition.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Newly Added 2TB Drive Not Utilized:&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;The Proxmox VM had a secondary &lt;strong&gt;2TB drive&lt;/strong&gt; (&lt;code&gt;/dev/sdb&lt;/code&gt;), but it was not formatted, mounted, or used.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Plex was relying on the small root partition for cache, transcoding, and metadata storage, causing failures.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Docker Storage Usage:&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Running &lt;code&gt;docker system df&lt;/code&gt; showed that there were no unused images or containers, so &lt;code&gt;docker system prune&lt;/code&gt; was not necessary.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;strong&gt;Resolution Steps:&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;To resolve the issue, we took the following steps:&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;Step 1: Free Up Space on Root Filesystem&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Clean APT cache:&lt;/strong&gt;
   &lt;code&gt;bash
   sudo apt clean&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Remove old logs:&lt;/strong&gt;
   &lt;code&gt;bash
   sudo journalctl --vacuum-time=3d
   sudo rm -rf /var/log/*.gz /var/log/*.1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Identify and remove large unnecessary files:&lt;/strong&gt;
   &lt;code&gt;bash
   sudo du -ahx / | sort -rh | head -20&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;strong&gt;Step 2: Mount the 2TB Drive and Move Plex Config and Transcoding Data&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Format the 2TB disk (&lt;code&gt;/dev/sdb&lt;/code&gt;):&lt;/strong&gt;
   &lt;code&gt;bash
   sudo mkfs.ext4 /dev/sdb&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Create a mount point:&lt;/strong&gt;
   &lt;code&gt;bash
   sudo mkdir -p /mnt/plex_config&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mount the new drive:&lt;/strong&gt;
   &lt;code&gt;bash
   sudo mount /dev/sdb /mnt/plex_config&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Move Plex configuration and transcode directories to the new drive:&lt;/strong&gt;
   &lt;code&gt;bash
   docker stop plex
   sudo mv /var/plex/config /mnt/plex_config/
   sudo mv /var/plex/transcode /mnt/plex_config/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ensure correct permissions:&lt;/strong&gt;
   &lt;code&gt;bash
   sudo chown -R administrator:administrator /mnt/plex_config&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Update Docker container settings to use the new location:&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Modify &lt;code&gt;docker-compose.yml&lt;/code&gt; or the &lt;code&gt;docker run&lt;/code&gt; command to reflect the new paths:
     &lt;code&gt;bash
     -v /mnt/plex_config/config:/config
     -v /mnt/plex_config/transcode:/transcode&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Persist the mount by adding it to &lt;code&gt;/etc/fstab&lt;/code&gt;:&lt;/strong&gt;
   &lt;code&gt;bash
   /dev/sdb /mnt/plex_config ext4 defaults 0 2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reboot and verify the mount persists:&lt;/strong&gt;
   &lt;code&gt;bash
   sudo reboot&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;strong&gt;Step 3: Restart Plex and Verify Functionality&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Start the Plex container:&lt;/strong&gt;
   &lt;code&gt;bash
   docker start plex&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Verify Plex is running without errors:&lt;/strong&gt;
   &lt;code&gt;bash
   docker logs plex -f&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Attempt media playback and confirm that transcoding works without errors.&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;strong&gt;Final Outcome:&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;✅ Plex no longer crashes due to disk space issues.&lt;br&gt;
✅ APT updates and system operations work without errors.&lt;br&gt;
✅ Transcoding and playback are stable.&lt;br&gt;
✅ The root filesystem has ample free space, preventing future failures.  &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Preventive Measures for Future Issues:&lt;/strong&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Monitor disk usage regularly:&lt;/strong&gt;
   &lt;code&gt;bash
   df -h
   docker system df&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Periodically clean up old logs and temporary files.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ensure new storage devices are properly formatted, mounted, and utilized as needed.&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;</content><category term="homelab"/><category term="homelab"/><category term="plex"/><category term="docker"/><category term="storage"/></entry></feed>